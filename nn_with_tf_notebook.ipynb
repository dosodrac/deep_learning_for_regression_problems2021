{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_CW1_dcard001.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAmee0BPx3u_"
      },
      "source": [
        "# **Artificial Intelligence Coursework 1**\n",
        "by David Cardoso (dcard001) | November 2021\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DauaBNpNyGDJ"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this coursework I will build a succession of Neural Networks (NN) with TensorFlow (TF) and search for the best configuration of hyperparameters to achieve the best model through the implementation of the universal workflow of machine learning, as presented in the book Deep Learning with Python [1]. I will be using the Boston House Pricing dataset to try to predict the median price of homes in a specific Boston suburb from the mid-1970s.\n",
        "First things first, Deep Learning (DL) is a new take on learning representations within Machine Learning (ML). DP allows computers to carry out classification, regression, and sequence prediction tasks with unprecedent accuracy levels. This is accomplished by it putting emphasis on learning successive layers of increasingly meaningful representations, with each layer learning by exposure to examples. This representations are learned via the use of NN. NN is a deep learning model made of a static sequence of computational layers stacked on top of each other. These layers extract “representations out of the data fed into them” [2].\n",
        "NN are composed of three different layers: Input layer, Hidden layer and Output layer as shown in figure 1.\n",
        "\n",
        "![NeuralNetworkDiagramResized.png](data:image/png;base64,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)\n",
        "\n",
        "[Fig. 01] - Neural Network structure\n",
        "\n",
        "Applications of DL can be found in a huge variety of industries. From automated driving to aerospace and medical research, DL is currently being used to decrease and prevent road accidents, locate areas of interest to drop troops, help researchers to identify cancer cells in very early stages, provide automated hearing and speech translation, among many other possible uses. Due to the ability to perform such tasks directly from images, text or sound, DL is revolutionizing our world in ways that we did not imagine.\n",
        "With this coursework I intend to explore and expand my knowledge on deep learning models and therefore possibly contribute for a more efficient and advanced future.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOlrIWRFNQWm"
      },
      "source": [
        "## **Methodology**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM03srhczuV2"
      },
      "source": [
        "###**Part 1: Defining the problem and assemblance of the dataset**\n",
        "For this coursework, I will understand if and how a deep learning model can be built in order to predict the median price of homes in a given Boston suburb in the mid-1970s through the use of Boston Housing Price dataset. Such dataset contains endemic data points, at the time, for example nitric oxides concentration, average number of rooms per dwelling and pupil-teacher ratio by town, among other out of a total of 13 features. \n",
        "\n",
        "I will import the dataset, load the data and check the key attributes of the tensor. A tensor is a container for data, almost always for numbers. It is defined by three key attributes:\n",
        "1.  Rank/dimension, the number of axes \n",
        "2.  Shape, the number of elements along each dimension\n",
        "3.  Type, the data type of the contained data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbSRGJ0f204"
      },
      "source": [
        "# Import and load dataset\n",
        "from keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3wiWudotqyC",
        "outputId": "2eba45bf-b887-47e1-b6fe-86c6ec68c9cf"
      },
      "source": [
        "# A quick examination of the data\n",
        "##  Check the tensor rank\n",
        "print('Rank:', train_data.ndim)\n",
        "##  Check the tensor shape\n",
        "print('Train data shape:', train_data.shape)\n",
        "print('Test data shape:', test_data.shape)\n",
        "##  Check the tensor type\n",
        "print('Data type:', train_data.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 2\n",
            "Train data shape: (404, 13)\n",
            "Test data shape: (102, 13)\n",
            "Data type: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRUXkIb6t06"
      },
      "source": [
        "Through the analyse of the dataset, it is perceptible that this dataset has 506 samples, 404 of which are training samples and the remaining 102 test samples, with each block of samples with 13 numerical features. This may be considered a small amount of data points.\n",
        "\n",
        "Due to this problem being finding only one answer among an infinite quantity of output, it is clear that this is a scalar regression problem, “a task where the target is a continuous scalar value” [2], a value that portrays the purposeful relationship between correlated variables, in this case the price of a property and its features. \n",
        "\n",
        "For this reason, I hypothesize that:\n",
        "\n",
        "1.   The deep learning model can predict the median price of home at that location and time, given the existent data.\n",
        "2.   The dataset has sufficient data and sufficient information so that the model will learn the relationship between input and output.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOMAzsgGKD4K"
      },
      "source": [
        "###**Part 2: Choosing a measure of success**\n",
        "\n",
        "In order to measure the success of my model, I first need to address how to measure it. For being a regression problem, it has different metrics from other types of problems. Whereas accuracy is expected and desired for a classification model, in this case the aim is to achieve the lowest possible absolute value difference between predictions and targets. This is called mean absolute error (MAE) and it provides a good metric to measure the performance of this model. \n",
        "\n",
        "Since the measure of success is MAE, naturally the loss function will be mean square error (MSE) I will optimise the mean square error in the loss function.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2kqJGsFKQ0z"
      },
      "source": [
        "###**Part 3: Deciding on an evaluation protocol**\n",
        "Th third part of the universal workflow is to decide on how to evaluate my current progress. I have chosen K-fold cross validation. This protocol is particularly efficient when there are not enough samples to use hold-out validation set. Cross-validation is used to evaluate models with restricted data samples and works through the following steps:\n",
        "1.\tShuffle the dataset randomly\n",
        "2.\tSplit the dataset into k groups of equal size\n",
        "3.\tIn each group\n",
        "  \n",
        "    a.\tUse the group as test data set\n",
        "    \n",
        "    b.\tUse the remaining groups as training data set\n",
        "    \n",
        "    c.\tFit a model on the training set and evaluate it on the test set\n",
        "    \n",
        "    d.\tKeep the validation value \n",
        "4.\tSum the validation scores and divide by the number of k groups, determining the average of all validations scores and therefore find the final score. [5]\n",
        "\n",
        "For this reasons, the value for k must be chosen carefully for it will hve implications on the bias of this technique. The lower the k value, the smaller the bias and the better the model will predict.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wQ6PLBF6ti5"
      },
      "source": [
        "###**Part 4: Preparing the data**\n",
        "\n",
        "In a neural network, a dataset can have a plethora of features with different values and ranges. Although manageable by the network, this would create unnecessary difficult to learn. So, to circumvent this, it is crucial to homogenise data. This is called normalization and is performed by Numpy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ5CASHT_fJI"
      },
      "source": [
        "# Normalization\n",
        "mean = train_data.mean(axis = 0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLQ9zd_gABAf"
      },
      "source": [
        "With the data normalized and ready to be used by the network, the next natural step is to build the network.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8xkYXFVARkc"
      },
      "source": [
        "###**Part 5: Better than a baseline**\n",
        "\n",
        "The fifth part of the universal workflow dictates that a basic model must be built with statistical power capabilities. This basic model must be capable of performing better than a baseline, proving that its results escape the probability of randomly predict successfully. \n",
        "I will now create a baseline to be used as comparison to the basic model. This baseline will be the result of the mean absolute error (MAE), the absolute value difference between predictions and targets. In this case, such value refers to the MAE of the average house prices. \n",
        "\n",
        "This will be the baseline as shown in the code bellow:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXRnRRLXaSFb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3z9e8xnOKlH",
        "outputId": "5abd5585-2653-440e-89ef-db3d6db03e59"
      },
      "source": [
        "import numpy as np\n",
        "mean = np.mean(train_targets)#  Find the mean of all house prices in the training data set\n",
        "baseline_mae = np.mean(np.abs(train_targets - mean))#  Calculation of the MAE\n",
        "print('Baseline MAE value:', baseline_mae)#  Baseline MAE value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE value: 6.647632585040682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB3pUi06_OTr"
      },
      "source": [
        "The baseline has been established so now the first model can be build."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10hfbq60Aiix",
        "outputId": "d03416fc-a6e3-4480-f40d-922aacc9eb84"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "#build model function\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  # adding layers to model\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "# Build the first model\n",
        "K = 4\n",
        "num_val_samples = len(train_data) // K\n",
        "num_epochs = 100 #  number of iteration over all the training data\n",
        "first_model_all_scores = [] # empty array\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    first_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPRQ1AGeQV9X",
        "outputId": "36ca6927-aebf-4323-c0d9-200db3944daa"
      },
      "source": [
        "first_model_mae = np.mean(first_model_all_scores)\n",
        "print('First model MAE value:',first_model_mae)#  First model MAE value\n",
        "print('Baseline MAE value:', baseline_mae)#  Baseline MAE value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First model MAE value: 2.3549145460128784\n",
            "Baseline MAE value: 6.647632585040682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSf0xdzuQvqZ"
      },
      "source": [
        "From the code blocks above, I can see that:\n",
        "\n",
        "1.   The baseline MAE ≈ 6.648.\n",
        "2.   The first mode MAE ≈ 2.447.\n",
        "\n",
        "Therefore, it is clear that this model has statistical power which translate to being capable of performing better than a dumb baseline, as the one set above. \n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FDCiFBkA7zG"
      },
      "source": [
        "###**Part 6: Scaling up**\n",
        "\n",
        "Proved that the model has statistical power, is time to greatly scale the model in order to find the point where validation starts to worsen and therefore find this model optimal number of epochs. \n",
        "\n",
        "An epoch  each iteration over all the training data which result in the update of the weights. An ideal model will place between underfitting and overfitting, so is crucial to find, among other aspects, the optimal number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFHHUhOnBHOW",
        "outputId": "71ee1ea8-aa83-4646-c12e-eccaa090d4da"
      },
      "source": [
        "# Scale up \n",
        "num_epochs = 500\n",
        "scalling_model_all_scores = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "  [train_data[:i * num_val_samples],\n",
        "  train_data[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "  [train_targets[:i * num_val_samples],\n",
        "  train_targets[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "\n",
        "  model = build_model()\n",
        "  # Train the model (in silent mode, verbose=0)\n",
        "  # Keeping validation logs after each fold\n",
        "  history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "\n",
        "  mae_history = history.history['val_mae']\n",
        "  scalling_model_all_scores.append(mae_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZMneUkFZSSm",
        "outputId": "03152565-d338-465c-e32a-901b0dc62b81"
      },
      "source": [
        "scalling_model_average_mae_history = [\n",
        "np.mean([x[i] for x in scalling_model_all_scores]) for i in range(num_epochs)]\n",
        "print(scalling_model_average_mae_history)#  Will print the average mae of each epoch (iteration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.426069796085358, 3.350998103618622, 3.031133532524109, 2.827149987220764, 2.737566828727722, 2.787208318710327, 2.6081913709640503, 2.5821109414100647, 2.675127387046814, 2.676555097103119, 2.616182506084442, 2.488396167755127, 2.431098520755768, 2.5425671339035034, 2.4702757000923157, 2.467419445514679, 2.4128143191337585, 2.363005429506302, 2.5069899559020996, 2.5639659762382507, 2.6553966999053955, 2.5369080901145935, 2.3578802943229675, 2.5314921736717224, 2.502234399318695, 2.593178927898407, 2.514721155166626, 2.535794258117676, 2.45413875579834, 2.3700888752937317, 2.3409948348999023, 2.385118216276169, 2.4328286051750183, 2.399429976940155, 2.398851215839386, 2.3638778924942017, 2.340831071138382, 2.3802566826343536, 2.645228624343872, 2.436071217060089, 2.5043018460273743, 2.454303115606308, 2.3110453486442566, 2.444317638874054, 2.382477104663849, 2.4550411105155945, 2.2866927087306976, 2.4202115535736084, 2.430555999279022, 2.62107253074646, 2.4519852995872498, 2.4374913573265076, 2.6760939359664917, 2.482324779033661, 2.423611104488373, 2.412639230489731, 2.4528395533561707, 2.3806275725364685, 2.422161817550659, 2.4973593950271606, 2.3893725275993347, 2.4538507759571075, 2.4208662509918213, 2.521952748298645, 2.499295562505722, 2.4702508449554443, 2.341060221195221, 2.4300696849823, 2.5051252841949463, 2.338970899581909, 2.4429402947425842, 2.556064248085022, 2.599116027355194, 2.463614583015442, 2.587148129940033, 2.4282650351524353, 2.355937123298645, 2.52789169549942, 2.8647186160087585, 2.490674316883087, 2.5388213396072388, 2.4840027689933777, 2.4429075121879578, 2.6299691200256348, 2.5830107927322388, 2.4682140350341797, 2.414398670196533, 2.5298306345939636, 2.519837498664856, 2.6676376461982727, 2.4913317561149597, 2.6638184785842896, 2.4516929388046265, 2.560279130935669, 2.522651493549347, 2.6183202266693115, 2.518723964691162, 2.526597797870636, 2.588388681411743, 2.676655352115631, 2.461887836456299, 2.5826069116592407, 2.6173874735832214, 2.534576714038849, 2.552350103855133, 2.4827390909194946, 2.6658666729927063, 2.5401790738105774, 2.6412139534950256, 2.5392187237739563, 2.703469753265381, 2.61572527885437, 2.7388700246810913, 2.5949175357818604, 2.546507477760315, 2.586134195327759, 2.651522219181061, 2.635419547557831, 2.617492914199829, 2.6407283544540405, 2.631059169769287, 2.620191991329193, 2.5772481560707092, 2.624386727809906, 2.599258303642273, 2.7325632572174072, 2.682950258255005, 2.645101010799408, 2.6471948623657227, 2.616522789001465, 2.6867916584014893, 2.7735655307769775, 2.7760475277900696, 2.612609326839447, 2.7386542558670044, 2.622303307056427, 2.6950113773345947, 2.5448012351989746, 2.665884792804718, 2.619921922683716, 2.7766459584236145, 2.6257686018943787, 2.725239634513855, 2.705438494682312, 2.7341421246528625, 2.6750588417053223, 2.644722819328308, 2.8015262484550476, 2.7172478437423706, 2.735137164592743, 2.709484279155731, 2.5812528133392334, 2.8057870268821716, 2.7005667686462402, 2.726068437099457, 2.741569399833679, 2.645370066165924, 2.642302930355072, 2.9152063131332397, 2.6332231760025024, 2.786420524120331, 2.805496633052826, 2.7420437932014465, 2.6647287011146545, 2.7256035208702087, 2.63364839553833, 2.7788925766944885, 2.70768404006958, 2.7470145225524902, 2.8102967739105225, 2.7713767886161804, 2.6920517086982727, 2.8522497415542603, 2.6868082880973816, 2.8070523738861084, 2.802947461605072, 2.7608394026756287, 2.8039451241493225, 2.8347796201705933, 2.68677020072937, 2.7780697345733643, 2.7484030723571777, 2.6918522715568542, 2.8015270829200745, 2.7112178206443787, 2.7272361516952515, 2.8759520053863525, 2.746308743953705, 2.724793791770935, 2.803329288959503, 2.7816567420959473, 2.795378088951111, 2.7915557622909546, 2.781221568584442, 2.8779731392860413, 2.731488347053528, 2.773005187511444, 2.8167583346366882, 2.840813100337982, 2.696203291416168, 2.7796157002449036, 2.783027708530426, 2.8813593983650208, 2.76982444524765, 2.7899267077445984, 2.813122034072876, 2.759497582912445, 2.763567268848419, 2.8610313534736633, 2.763894498348236, 2.799796164035797, 2.7602608799934387, 2.820278823375702, 2.8990283608436584, 2.8495882749557495, 2.9771918058395386, 2.81045663356781, 2.7759474515914917, 2.8917505741119385, 2.7126614451408386, 2.8134642243385315, 2.8803380131721497, 2.945420563220978, 2.923677682876587, 2.80360347032547, 2.746833324432373, 2.7212103605270386, 2.960113227367401, 2.752641201019287, 2.8686580061912537, 2.8723104000091553, 2.7324782013893127, 2.9369693398475647, 2.911669433116913, 2.763232409954071, 2.8751572966575623, 2.772991895675659, 2.8976974487304688, 2.8750333189964294, 2.8409833908081055, 2.8098923563957214, 2.765225410461426, 2.8815362453460693, 2.9603243470191956, 2.975016236305237, 2.8523377776145935, 2.9301000237464905, 2.902529716491699, 2.8287317752838135, 3.069356143474579, 2.8418951630592346, 2.8387539386749268, 2.860837996006012, 2.854479193687439, 2.82501882314682, 2.847878336906433, 2.9053595066070557, 2.900443911552429, 2.865597367286682, 2.843213140964508, 2.8545485734939575, 2.8161700963974, 2.9110560417175293, 2.8756638765335083, 2.8972541093826294, 2.9731136560440063, 2.81244432926178, 2.84836345911026, 2.8038657307624817, 2.8595136404037476, 2.9416300654411316, 2.924103617668152, 2.8753950595855713, 2.9388696551322937, 2.8163593411445618, 2.8731998205184937, 3.0491586923599243, 2.973154604434967, 2.9660187363624573, 2.888739764690399, 2.954180598258972, 2.9058678150177, 2.889888346195221, 2.813149571418762, 2.9464677572250366, 2.889760136604309, 2.8074414134025574, 2.958495080471039, 2.8810776472091675, 2.8609890937805176, 2.9410274028778076, 2.838403582572937, 2.883649706840515, 2.927466332912445, 2.8475881218910217, 2.875249981880188, 2.8772009015083313, 2.8956077098846436, 2.8293911814689636, 2.833886504173279, 2.8408508896827698, 2.792336165904999, 3.023048222064972, 2.8295761942863464, 2.7785549759864807, 2.9030433893203735, 2.894905924797058, 2.736432373523712, 2.821585774421692, 2.850705564022064, 2.8712894916534424, 2.846293032169342, 2.8525179028511047, 2.895169198513031, 2.936497449874878, 2.866948962211609, 2.8502167463302612, 2.8592693209648132, 2.8561823964118958, 2.831580698490143, 2.88339501619339, 2.868119478225708, 2.8861005306243896, 2.808468997478485, 2.7588587403297424, 2.8830478191375732, 2.7366201281547546, 2.8097176551818848, 2.927795946598053, 2.8045093417167664, 2.844955265522003, 2.7802423238754272, 2.877128005027771, 2.9536250829696655, 2.9332377910614014, 2.7688740491867065, 2.8477291464805603, 2.798612117767334, 2.76784211397171, 2.8269285559654236, 2.789560556411743, 2.9565622210502625, 2.8406078219413757, 2.836163103580475, 2.773970901966095, 2.7739295959472656, 2.7927494049072266, 2.782942235469818, 2.8853697180747986, 2.8105921149253845, 2.7877591848373413, 2.8347219824790955, 2.7641438841819763, 2.720802426338196, 2.8317657709121704, 2.847073256969452, 2.775097072124481, 2.872993528842926, 2.8001990914344788, 2.7923699617385864, 2.828967869281769, 2.835074484348297, 2.8544914722442627, 2.8554129004478455, 2.8322701454162598, 2.780485451221466, 2.7960792779922485, 2.7413337230682373, 2.7929734587669373, 2.7830119132995605, 2.783073842525482, 2.9101462960243225, 2.7729400396347046, 2.931232273578644, 2.91765558719635, 2.862120032310486, 2.836550712585449, 2.713776111602783, 2.8608570098876953, 2.903716027736664, 2.7724231481552124, 2.683465600013733, 2.7824559807777405, 2.772397756576538, 2.724694013595581, 2.78065025806427, 2.82547390460968, 2.748737871646881, 2.8014033436775208, 2.759203255176544, 2.7441933155059814, 2.7684273719787598, 2.767562687397003, 2.753555119037628, 2.8765934705734253, 2.738901436328888, 2.8781567215919495, 2.790421426296234, 2.8620468974113464, 2.712100327014923, 2.8139782547950745, 2.782746136188507, 2.657948613166809, 2.818313181400299, 2.7131402492523193, 2.7130930423736572, 2.84330952167511, 2.817861795425415, 2.768250823020935, 2.703805387020111, 2.7856699228286743, 2.7470184564590454, 2.8761309385299683, 2.7602643370628357, 2.715120494365692, 2.8581746220588684, 2.72639262676239, 2.744126260280609, 2.783361852169037, 2.904809892177582, 2.794963538646698, 2.810095489025116, 2.784924268722534, 2.885650873184204, 2.777611255645752, 2.6849438548088074, 2.751447081565857, 2.7129750847816467, 2.6781809329986572, 2.7750394344329834, 2.780681610107422, 2.777056097984314, 2.803695261478424, 2.8259469270706177, 2.7903552055358887, 2.7544105052948, 2.831172227859497, 2.666542708873749, 2.774319112300873, 2.8344712257385254, 2.779473125934601, 2.715751528739929, 2.758282721042633, 2.762975811958313, 2.811306655406952, 2.7529048919677734, 2.9405941367149353, 2.743991196155548, 2.815171778202057, 2.7602630853652954, 2.745613992214203, 2.746870458126068, 2.7790523767471313, 2.7539857625961304, 2.8133269548416138, 2.636937201023102, 2.764632225036621, 2.7240402698516846, 2.68523770570755, 2.738473355770111, 2.743612051010132, 2.7664846777915955, 2.680477559566498, 2.8177242279052734, 2.838927924633026, 2.757607877254486, 2.806577444076538, 2.652274191379547, 2.751899540424347, 2.666357457637787, 2.67433100938797, 2.7011850476264954, 2.655124068260193, 2.761703670024872, 2.709939658641815, 2.750460982322693, 2.7545804381370544, 2.708311915397644, 2.826215386390686, 2.698586344718933, 2.7310497164726257, 2.701353967189789, 2.719724118709564, 2.696998178958893, 2.8021841645240784, 2.7148013710975647, 2.6965449452400208, 2.6909794211387634, 2.783364772796631, 2.8374162912368774, 2.676651656627655, 2.843571424484253, 2.7409106492996216, 2.756488263607025, 2.7135666608810425, 2.73805695772171, 2.7309391498565674, 2.737349808216095, 2.744040608406067, 2.7837659120559692]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruq962wQeBmo"
      },
      "source": [
        "The code bellow plots the mean MAE for each of the 500 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "qMxbbN9JfTEL",
        "outputId": "94b36177-cdaf-4ed8-d513-c73ee5199428"
      },
      "source": [
        "# Plotting all the validation scores\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot the average MAE for each epoch\n",
        "plt.plot(range(1, len(scalling_model_average_mae_history) + 1), scalling_model_average_mae_history)\n",
        "\n",
        "# Axes labbels\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwnu6UNUefWs"
      },
      "source": [
        "Due to the enourmous amount of epochs needed to overfit, isnt clear what is the optimal number of epochs. For that reason, I will remove the first 10 MAE values so that readibility is improved.\n",
        "\n",
        "On top of that, I will use a smoothing function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Px5B1_7efrpb",
        "outputId": "0fecd2c1-3a45-4304-bf66-218eb0c16558"
      },
      "source": [
        "# Plotting validation scores, excluding the first 10 data points for clarity\n",
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "# Smoothing the points to make it more readable\n",
        "smooth_mae_history = smooth_curve(second_model_average_mae_history[10:])\n",
        "\n",
        "#new update graph\n",
        "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNwL9M9oUq1M"
      },
      "source": [
        "Netx, I will find the minimum value so that is clear when will the validation degrade for the lower the validation loss, the better the model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gV3yYKiUhRJ",
        "outputId": "e752a749-45ce-492b-ee4e-283c55d03d15"
      },
      "source": [
        "num_epochs = np.argmin(smooth_mae_history)\n",
        "print('Optimal number of epochs: ', num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of epochs:  35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8mC6sldRPcC",
        "outputId": "625b84a7-6a14-4fad-aa7c-e0ff3608cdf8"
      },
      "source": [
        "# Optimal number of epochs model\n",
        "epochs_model_all_scores = []\n",
        "for i in range(k):\n",
        "  print('processing fold #', i)\n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "  partial_train_data = np.concatenate(\n",
        "  [train_data[:i * num_val_samples],\n",
        "  train_data[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "  partial_train_targets = np.concatenate(\n",
        "  [train_targets[:i * num_val_samples],\n",
        "  train_targets[(i + 1) * num_val_samples:]],\n",
        "  axis=0)\n",
        "\n",
        "  model = build_model()\n",
        "  # Train the model (in silent mode, verbose=0)\n",
        "  model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "  # Evaluate the model on the validation datam\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "  epochs_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67iL03GtdOpI",
        "outputId": "30a9e4db-c7b5-4bcf-c2b7-2b3d0e701a4c"
      },
      "source": [
        "epochs_model_all_scores = np.mean(epochs_model_all_scores)\n",
        "print('Optimal epochs model MAE: ', epochs_model_all_scores)\n",
        "print('Previous model MAE: ', first_model_mae)\n",
        "print('MAE decrease: ', first_model_mae - epochs_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal epochs model MAE:  2.443190336227417\n",
            "Previous model MAE:  2.3549145460128784\n",
            "MAE decrease:  -0.08827579021453857\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-P0VvpiV_Sw"
      },
      "source": [
        "The optimal number of epochs for this model build is 35. From the code above is clear that with the use of the optimal number of epochs, the model's MAE decreased, therefore improving the current model comparing to the first model.\n",
        "\n",
        "The next step is to regularize and tune the model to find the optimal configuration and so reach best deep learning model possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS267TFeeI9c"
      },
      "source": [
        "### **Part 7: Regularizing and tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipL69PHrfGMM"
      },
      "source": [
        "In the last part of the universal workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d56nmDLQWheg"
      },
      "source": [
        "####  **Adding weight regularization**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koYL1XnGofs3"
      },
      "source": [
        "\n",
        "In the last part of the universal workflow, I will regularize and tune the model. By changing the models’ hyperparameters and analyse its subsequent change in performance I will be able to identify the best configuration among the hyperparameters chosen, using the MAE as a validation aspect.\n",
        "\n",
        "Before tuning the model, it needs to be regularized. This process fights overfitting through the application of measures such as adding more data, network size reduction, weight regularization and adding dropout. I chose to add weight regularization which consists in putting limits on the complexity of a network by forcing its weights to only admit small values. I will experiment L1 and L2 regularization in turns and then altogether. This is added by passing weight regularizer instances to layers as keyword arguments [2].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGtbmcl-jLzc"
      },
      "source": [
        "##### **L1 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEt3KBVC3WJg",
        "outputId": "b0b75abd-7f2b-4cc4-a63e-62715cca8016"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# build the third model adding L1 regularizer\n",
        "def build_l1model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l1(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "l1_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_l1model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    l1_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ2uDDoMZKIj",
        "outputId": "718b9fe0-a5e9-41c0-e51e-99991a5ae212"
      },
      "source": [
        "l1_model_all_scores = np.mean(l1_model_all_scores)\n",
        "print('L1 model with weight regularization MAE: ', l1_model_all_scores)\n",
        "print('MAE decreased from first model by: ', (first_model_mae - l1_model_all_scores))\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 model with weight regularization MAE:  2.489901840686798\n",
            "MAE decreased from first model by:  -0.13498729467391968\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXR-_jxgpNng"
      },
      "source": [
        "Comparing the first MAE value of weight regularization with the MAE value from the first model, it is clear that the MAE value got worse which means that L1 is not an improvement when compared to the first model built here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch_2rFU2jcrq"
      },
      "source": [
        "##### **L2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izrw6rp7H_38",
        "outputId": "bb89d90e-b905-48d8-bf25-d914770cbcc8"
      },
      "source": [
        "# build the fourth model adding L2 regularizer\n",
        "def build_l2model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "l2_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_l2model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    l2_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cehrUS7qaJO6",
        "outputId": "2a0826b6-027f-4bdb-87e9-468f4d172cca"
      },
      "source": [
        "l2_model_all_scores = np.mean(l2_model_all_scores)\n",
        "print('L2 model with weight regularization MAE: ',l2_model_all_scores)\n",
        "print('MAE decreased from first model by: ', (first_model_mae - l2_model_all_scores))\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 model with weight regularization MAE:  2.267015188932419\n",
            "MAE decreased from first model by:  0.0878993570804596\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgDO-wvWp5mz"
      },
      "source": [
        "Contrary to L1 MAE value, the code above shows that L2 weight regularization does improve the MAE value when compared to the first model built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY3pOrwKjffU"
      },
      "source": [
        "##### **L1+L2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFih_XfqKPpO",
        "outputId": "9f0eae07-7f09-47bc-8f7e-9b9e81edb813"
      },
      "source": [
        " # build the fifth model adding L1+L2 regularizers\n",
        "def build_l1l2model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "l1l2_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_l1l2model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    l1l2_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV7jUeoNaOyG",
        "outputId": "97593631-fb57-4dd0-cfa7-8ed2b0d33424"
      },
      "source": [
        "l1l2_model_all_scores = np.mean(l1l2_model_all_scores)\n",
        "print('L1+L2 model with weight regularization MAE: ',l1l2_model_all_scores)\n",
        "print('MAE decreased from first model by: ', (first_model_mae - l1l2_model_all_scores))\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1+L2 model with weight regularization MAE:  2.4330516159534454\n",
            "MAE decreased from first model by:  -0.07813706994056702\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY3G7U6DqgZL"
      },
      "source": [
        "After a escalation with L1 and a depreciation with L2, the third weigh regularization combined the use of L1 and L2 which translated in a growth of 0.078 when compared to the first model built. Still better than L1 but a growth none the less. It it important to remember that the lower the MAE value, the better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qww2M-yOLufy"
      },
      "source": [
        "Having tried the three types of weight regularizers, I will compare the three results and identify the optimal regularizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnhm2Gt3BcV"
      },
      "source": [
        "##### **Weight regularization comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28ImkLdL66S",
        "outputId": "85d569f0-5935-4eba-f291-7cfd2c6cade2"
      },
      "source": [
        "print('L1 Model MAE:    ',l1_model_all_scores)\n",
        "print('L2 Model MAE:    ',l2_model_all_scores)\n",
        "print('L1+L2 Model MAE: ',l1l2_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Model MAE:     2.489901840686798\n",
            "L2 Model MAE:     2.267015188932419\n",
            "L1+L2 Model MAE:  2.4330516159534454\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtwWXwxENV3L"
      },
      "source": [
        "From the code above, it is clear that the L2 weight regularization produced the lowest MAE, hence the best model so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt-sAWLqXYnv"
      },
      "source": [
        "#### **Tuning the type of optimizer**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwOUveIGV8hc"
      },
      "source": [
        "When training a neural network, its weights are initially randomly initialized only to be then updated in each epoch. [4] This way they increase the overall accuracy of the network. The optimizer job is to specify the exact way in which the gradient of the loss will be used to update the parameters. Through the correct regulation on the weights update, the optimizer makes sure that accuracy will be as high as possible. \n",
        "\n",
        "There are 8 different types of optimizer, and I will use three of them as measuring tool to improve the model viability: Rmsprop, Adam and Adadelta. I will then calculate the mean MAE for each optimizer and use that value as validation on the most efficient optimizer.\n",
        "[3] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brENtQYUwXrd"
      },
      "source": [
        "##### **Opt1 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uHlX62VsE4v"
      },
      "source": [
        "As first choice of optimizer, I will use Rmsprop which is the default optimizer. This way the MAE value produced will work as a base value and all the other will compare to this first option. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6_Q376tYXC1",
        "outputId": "1f6c931c-bd87-432a-a206-ae3beae4fd2f"
      },
      "source": [
        "# build the optimizer 1 model\n",
        "def build_opt1_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # Optimizer Rmsprop\n",
        "  return model\n",
        "\n",
        "opt1_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_opt1_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    opt1_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aozIFfCXwRfY",
        "outputId": "990c6c54-5f9f-4fa9-f3ba-65c772d71f02"
      },
      "source": [
        "opt1_model_all_scores = np.mean(opt1_model_all_scores)\n",
        "print('Opt1 model MAE: ',opt1_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opt1 model MAE:  2.4154313504695892\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYcCAHyOw0A_"
      },
      "source": [
        "##### **Opt2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSFqCkBpxA_E",
        "outputId": "21e4b283-f821-4936-aaff-873d1188a6af"
      },
      "source": [
        "# build the optimizer 2 model\n",
        "def build_opt2_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mae'])# Optimizer Adam\n",
        "  return model\n",
        "\n",
        "opt2_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_opt2_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    opt2_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp1DZ8daxN_N",
        "outputId": "2403e4d5-0ff8-421b-87da-8f0efe5af7da"
      },
      "source": [
        "opt2_model_all_scores = np.mean(opt2_model_all_scores)\n",
        "print('Opt2 model MAE: ',opt2_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opt2 model MAE:  2.4089295566082\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LwAmnVZzdsg"
      },
      "source": [
        "##### **Opt3 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn_YsJJGzhdy",
        "outputId": "1c41e4c3-bbc2-43eb-f3aa-d3ce7c1fecbd"
      },
      "source": [
        "# build the optimizer 3 model\n",
        "def build_opt3_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='adadelta', loss='mse', metrics=['mae'])# Optimizer Adadelta\n",
        "  return model\n",
        "\n",
        "opt3_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_opt3_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    opt3_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqQk6I-kzsXQ",
        "outputId": "a4fb4c75-6587-477d-d724-5f98f32efdb5"
      },
      "source": [
        "opt3_model_all_scores = np.mean(opt3_model_all_scores)\n",
        "print('Opt3 model MAE: ',opt3_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opt3 model MAE:  22.20896339416504\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0ZBY5yi2z47"
      },
      "source": [
        "##### **Optimizer comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhYJI0XC1Jai",
        "outputId": "d63bfe45-616b-4815-867a-550b85f3680f"
      },
      "source": [
        "print('Opt1 Model MAE: ',opt1_model_all_scores)\n",
        "print('Opt2 Model MAE: ',opt2_model_all_scores)\n",
        "print('Opt3 Model MAE: ',opt3_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opt1 Model MAE:  2.4154313504695892\n",
            "Opt2 Model MAE:  2.4089295566082\n",
            "Opt3 Model MAE:  22.20896339416504\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqMsLpxnsfUG"
      },
      "source": [
        "Analysing the three outputs of the three chosen different optimizers, is perceptible that optimizer Adadelta breaks the limit of all the others MAEs whilst Rmsprop and Adam barely can be distinguished for their MAE value differ less than 0.1. It is clear then that Adam is the best option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80cXKdLtX3TJ"
      },
      "source": [
        "#### **Tuning the learning rate**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFFoIzD9WDPa"
      },
      "source": [
        "The last hyperparameter to be tuned is learning rate. This step is how much the weights are updated during training. \n",
        "\n",
        "Learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. It controls how quickly the model adapts.\n",
        "\n",
        "Sudden changes in the learning rate can cause the model to converge too quickly to a non ideal solution, so my tuning will be cautious. \n",
        "I will start with 0.001, the lowest of the three values that I will put to test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU_Iv_qi3KXL"
      },
      "source": [
        "##### **LR1 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yN0s1ul3EJZ",
        "outputId": "7facfdce-b7e7-4742-b1a2-9270d4ad9419"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# build the learning rate 1 model\n",
        "def build_lr1_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer = optimizers.Adam(learning_rate = 0.001), loss = 'mse', metrics = ['mae'])\n",
        "  return model\n",
        "\n",
        "lr1_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_lr1_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    lr1_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY1YnoHD7EQ-",
        "outputId": "e2c6414a-9edb-4c1c-f162-5ad15f889ecf"
      },
      "source": [
        "lr1_model_all_scores = np.mean(lr1_model_all_scores)\n",
        "print('LR1 model MAE: ',lr1_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR1 model MAE:  2.3689284920692444\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-oshYzWuLdr"
      },
      "source": [
        "Straight away, learning rate 0.001 reached one of the lowest MAE values so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnopSmtn7ZqD"
      },
      "source": [
        "##### **LR2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiMMiugJ7dCR",
        "outputId": "aa277901-df5e-4f4e-f8a9-f457c41cf71e"
      },
      "source": [
        "# build the learning rate 2 model\n",
        "def build_lr2_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer = optimizers.Adam(learning_rate = 0.005), loss = 'mse', metrics = ['mae'])\n",
        "  return model\n",
        "\n",
        "lr2_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_lr2_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    lr2_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P6UcGuG7i9g",
        "outputId": "79bd6819-9794-4bff-bf36-d21d1d9bf5a2"
      },
      "source": [
        "lr2_model_all_scores = np.mean(lr2_model_all_scores)\n",
        "print('LR1 model MAE: ',lr2_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR1 model MAE:  2.5668163895606995\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdSsF9XE7px1"
      },
      "source": [
        "#####**LR3 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRlQFjl47s-f",
        "outputId": "3f878f64-1560-42b6-e017-1a19bdbcaa3f"
      },
      "source": [
        "# build the learning rate 3 model\n",
        "def build_lr3_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer = optimizers.Adam(learning_rate = 0.01), loss = 'mse', metrics = ['mae'])\n",
        "  return model\n",
        "\n",
        "lr3_model_all_scores = []\n",
        "\n",
        "for i in range(K):\n",
        "    print('processing fold', i)\n",
        "    \n",
        "    # Prepare the validation data: data from partition i\n",
        "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
        "    val_data = train_data[a : b]\n",
        "    val_targets = train_targets[a : b]\n",
        "    \n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate([train_data[:a], train_data[b:]], axis=0)\n",
        "    partial_train_targets = np.concatenate([train_targets[:a], train_targets[b:]], axis=0)\n",
        "    \n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_lr2_model()\n",
        "    \n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # Evaluate the model on the validation datam\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    lr3_model_all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing fold 0\n",
            "processing fold 1\n",
            "processing fold 2\n",
            "processing fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UlotVRY734H",
        "outputId": "4e98608c-724f-4fe0-c53b-70c6b99683e8"
      },
      "source": [
        "lr3_model_all_scores = np.mean(lr3_model_all_scores)\n",
        "print('LR3 model MAE: ',lr3_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR1 model MAE:  2.5154531598091125\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyVxeruw3DQk"
      },
      "source": [
        "##### **Learning rate comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1olpQ0T798d",
        "outputId": "d6989fd9-88f4-49d8-89fb-d4dee6e6b0db"
      },
      "source": [
        "print('LR1 Model MAE: ',lr1_model_all_scores)\n",
        "print('LR2 Model MAE: ',lr2_model_all_scores)\n",
        "print('LR3 Model MAE: ',lr3_model_all_scores)\n",
        "print('----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR1 Model MAE:  2.3689284920692444\n",
            "LR2 Model MAE:  2.5668163895606995\n",
            "LR3 Model MAE:  2.5154531598091125\n",
            "----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6m2BmGvufu_"
      },
      "source": [
        "Comparing the three MAE value for different rates, becomes clear that the lowest value actually reach one of the lowest MAE value of all the models whereas the higher learning rates, go above the average MAE value of 2.42."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEe1Ex_RuYKP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO2XHfM-yPnE"
      },
      "source": [
        "## **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yO_KAkfxWSi"
      },
      "source": [
        "The following table condense all the models and respective configurations run in this coursework: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0lGjT8Js1JF"
      },
      "source": [
        "| Model Number  | Model Name  | Weight regularization  | Type of Optimizer  |  Learning Rate | MAE (3 d.p.) |\n",
        "| ------------ | ------------ | ------------ | ------------ | ------------ | ------------ |\n",
        "|  N/A | baseline  | N/A  | N/A  |  N/A | 6.648  |\n",
        "| 1  | first_model |  Default |Default|Default|  2.355 |\n",
        "|  2 | epochs_model  | Default  | Default  | Default  | 2.443  |\n",
        "|  3 | l1_model  |  L1 (0.001) | Default  | Default  | 2.490  |\n",
        "|  4 | l2_model  | L2 (0.001) | Default  | Default  | 2.267  |\n",
        "|  5 | l1l2_model   | L1+L2 (0.001 each) | Default  | Default  | 2.433  |\n",
        "| 6  | opt1_model  | L2  |Rmsprop| Default  | 2.415  |\n",
        "|  7 | opt2_model  | L2  | Adam  | Default  | 2.409  |\n",
        "|  8 | opt3_model  | L2  | Adadelta  | Default  | 22.209  |\n",
        "| 9  | lr1_model  | L2  | Adam  | 0.001  |2.369   |\n",
        "|  10 |lr2_model| L2  | Adam  |  0.005 |  2.567 |\n",
        "| 11  | lr3_model  | L2  | Adam  | 0.01  |  2.515 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhtyprXoPDpE"
      },
      "source": [
        "The following table condense all the models and respective configurations run in this coursework: \n",
        "\n",
        "\n",
        "A thorough scrutiny of the information present in the table, allows to conclude that:\n",
        "\n",
        "\n",
        "*  The first model has nearly 3 times more accuracy than the baseline.\n",
        "\n",
        "*  The optimal weight regularization is L2 at 0.001, with a MAE of 2.267.\n",
        "\n",
        "*  The optimal optimizer is Adam, with a MAE of 2.409.\n",
        "\n",
        "*  The optimal learning rate is 0.001, with a MAE of 2.369.\n",
        "\n",
        "*  There is an amplitude of 19.942 between the lowest and the highest MAE.\n",
        "\n",
        "From all the 11 models built, the \"l2_model\" proved to be the best model for this problem hence I will use it’s configuration for my final model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpzDGH-Ixd9y"
      },
      "source": [
        "### **Final model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_WoGyGXSEib"
      },
      "source": [
        "Following the evaluation of the result table in the previous section, I will built my model with the following configuration:\n",
        "\n",
        "\n",
        "*   35 Epochs.\n",
        "*   Weight regularization of L2 (0.001).\n",
        "*   Default optimizer.\n",
        "*   Default learning rate.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zMWUuCPQgq",
        "outputId": "c5fd6c5b-d61c-498c-df0c-a5f5a465250a"
      },
      "source": [
        "from keras import regularizers\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# build the final model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(train_data.shape[1],)))\n",
        "model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model (in silent mode, verbose=0)\n",
        "model.fit(train_data, train_targets, epochs=35, batch_size=1, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
        "print('Score: ', test_mae_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 15.3148 - mae: 2.4583\n",
            "Score:  2.4583396911621094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op9ytlKWS_Y8"
      },
      "source": [
        "##**Conclusion**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRA7R2J5u3Go"
      },
      "source": [
        "This was my first incursion into deep learning and, while using information provided by the book and the module teacher was relatively easy, the vast and varied possibilities provided by Machine Learning models make me consider that it is far more complex, comprehensive and with more applications that I know for now. From the extensive number of models built, I can conclude that L2 weigh regularization is the hyperparameter that better tunes down the MAE value, right after to learning rate 0.001 mixed with Adam optimizer, therefore this is something that I will use in the future. This type of information is only possible due to the experiments provided by this coursework.\n",
        "Looking closely to the table of results, the mean MAE is 2.4263, excluding the baseline and opt3_model which clearly pushed the scale up.\n",
        "\n",
        "So, the MAE of 2.4583 obtained by the final model makes me accept that it sits close to the average of all the other models. This also means that, although tuning the hyperparameters provided big changes in the output for some configurations, in the end the final model sits just by the mean average MAE value. Additionally, the final MAE shows a decreased of the baseline from 6.648 to 2.4583 proving that the scalar regression problem is possible of prediction despite the small dataset present.\n",
        "\n",
        "In conclusion, I believe that this coursework proved that the hypothesis were right: this deep learning model can predict the median price of a house in that area/time and the data points provided by Boston Housing dataset proved to be enough to allow the model to learning the relationship between input and output while achieving the first hypothesis point.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BVna-CpyTQJ"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] Chollet, F., 2018. Deep Learning with Python. 2nd ed. Manning Publications Co., pp.111 - 117.\n",
        "\n",
        "[2] Chollet, F., 2018. Deep Learning with Python. 2nd ed. Manning Publications Co.\n",
        "\n",
        "[3] Team, K., 2021. Keras documentation: Optimizers. [online] Keras.io. Available at: <https://keras.io/api/optimizers/> [Accessed 20 November 2021].\n",
        "\n",
        "[4] Sharma, P., 2020. Keras Optimizers Explained with Examples for Beginners - MLK - Machine Learning Knowledge. [online] MLK - Machine Learning Knowledge. Available at: <https://machinelearningknowledge.ai/keras-optimizers-explained-with-examples-for-beginners/#Comparison_of_Optimizers> [Accessed 20 November 2021].\n",
        "\n",
        "[Fig. 01] Disci, S., 2021. Simulated Neural Network with Bootstrapping Time Series Data | R-bloggers. [online] R-bloggers. Available at: <https://www.r-bloggers.com/2021/06/simulated-neural-network-with-bootstrapping-time-series-data/> [Accessed 18 November 2021].\n",
        "\n",
        "[5] Brownlee, J., 2018. A Gentle Introduction to k-fold Cross-Validation. [online] Machine Learning Mastery. Available at: <https://machinelearningmastery.com/k-fold-cross-validation/> [Accessed 18 November 2021]."
      ]
    }
  ]
}